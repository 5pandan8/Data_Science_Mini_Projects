{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Mini Project 3</h1></center>\n",
    "<br>\n",
    "<center><font size=\"5\">Name - Spandan Patil</font></center>\n",
    "<br>\n",
    "<center><font size=\"4\">AReM Data</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Time Series Classification Part 1: Feature Creation/Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import bootstrapped.bootstrap as bs\n",
    "import bootstrapped.stats_functions as bs_stats\n",
    "from scipy.stats import skew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the AReM Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bending1', 'bending2', 'cycling', 'lying', 'sitting', 'standing', 'walking']\n"
     ]
    }
   ],
   "source": [
    "# Getting a list of all classes for which we are having datasets.\n",
    "path = Path(\"../data/AReM\")\n",
    "categories = [f.name for f in path.iterdir() if f.is_dir()]\n",
    "\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Test and Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary of cls having a list containing path to each of the training dataset.\n",
    "train_set = defaultdict(list)\n",
    "\n",
    "for cls in categories:\n",
    "    if cls == 'bending1':\n",
    "        for i in range(3, 8): \n",
    "            train_set[cls].append(f\"../data/AReM/{cls}/dataset{i}.csv\")\n",
    "    elif cls == 'bending2':\n",
    "        for i in range(3, 7): \n",
    "            train_set[cls].append(f\"../data/AReM/{cls}/dataset{i}.csv\")\n",
    "    else:\n",
    "        for i in range(4, 16):\n",
    "            train_set[cls].append(f\"../data/AReM/{cls}/dataset{i}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary of cls having a list containing path to each of the testing dataset.\n",
    "test_set = defaultdict(list)\n",
    "\n",
    "for cls in categories:\n",
    "    if cls == 'bending1' or cls == 'bending2':\n",
    "        for i in range(1, 3): \n",
    "            test_set[cls].append(f\"../data/AReM/{cls}/dataset{i}.csv\")\n",
    "    else:\n",
    "        for i in range(1, 4):\n",
    "            test_set[cls].append(f\"../data/AReM/{cls}/dataset{i}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### i. Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following Time-domain features are commonly used in time series classification include:\n",
    "\n",
    "<ul>\n",
    "    <li>Minimum: The lowest value in the time series.</li>\n",
    "    <li>Maximum: The highest value in the time series.</li>\n",
    "    <li>Mean: The average value of the time series.</li>\n",
    "    <li>Median: The middle value when the time series is ordered.</li>\n",
    "    <li>Standard deviation: A measure of the spread of values in the time series.</li>\n",
    "    <li>First quartile: The 25th percentile of the ordered time series.</li>\n",
    "    <li>Third quartile: The 75th percentile of the ordered time series.</li>\n",
    "    <li>Variance: A measure of variability in the time series.</li>\n",
    "    <li>Higher-order moments: Statistical measures beyond mean and variance.</li>\n",
    "    <li>Coefficients of an AR (Autoregressive) model: Parameters that capture the dynamic behavior of the time series.</li>\n",
    "    <li>Energy in specific frequency intervals: Obtained from Discrete Fourier Transform (DFT) or Discrete Wavelet Transform (DWT).</li>\n",
    "</ul>\n",
    "\n",
    "src - https://stats.stackexchange.com/questions/50807/features-for-time-series-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### ii. Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of all the columns which will be present in our new dataset having the time domain features.\n",
    "cols = ['Instance']\n",
    "for i in range(1, 7):\n",
    "    cols.extend([f'min{i}', f'max{i}', f'mean{i}', f'median{i}', f'std{i}', f'1st_quart{i}', f'3rd_quart{i}'])\n",
    "\n",
    "# Creating an empty dataframe with the list of columns.\n",
    "extracted_df = pd.DataFrame(columns=cols)\n",
    "\n",
    "# Creating a list of columns present in our dataset, to keep with reading the csv files.\n",
    "inst_cols = [\"time\", \"avg_rss12\", \"var_rss12\", \"avg_rss13\", \"var_rss13\", \"avg_rss23\", \"var_rss23\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading all the training datasets.\n",
    "\n",
    "# For each of the classes in our training dictionary\n",
    "for cls in train_set:\n",
    "    # We get the index and path for that dataset.\n",
    "    for idx, inst_path in enumerate(train_set[cls]):\n",
    "        # Here we are handling the special case for bending2/dataset4.csv by using space as a separator instead of comma.\n",
    "        if cls == \"bending2\" and idx == 1:\n",
    "            # Reading the csv into a dataframe.\n",
    "            df = pd.read_csv(inst_path, sep=\" \", skiprows=5, header=None, names=inst_cols, usecols=range(7))\n",
    "        else:\n",
    "            df = pd.read_csv(inst_path, skiprows=5, header=None, names=inst_cols, usecols=range(7))\n",
    "        # Here we are creating a new row which will be appended to our dataframe having all the time domain features we require from this dataset.\n",
    "        new_row = []\n",
    "        new_row.append(len(extracted_df)+1)\n",
    "        # We are considering only the 6 time series data, ignoring the time column.\n",
    "        for i in range(1, 7):\n",
    "            new_row.extend([np.min(df[df.columns[i]]), np.max(df[df.columns[i]]), np.mean(df[df.columns[i]]), np.median(df[df.columns[i]]), np.std(df[df.columns[i]]), np.percentile(df[df.columns[i]], 25), np.percentile(df[df.columns[i]], 75)])\n",
    "        extracted_df.loc[len(extracted_df)] = new_row        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading all the testing datasets.\n",
    "\n",
    "# For each of the classes in our testing dictionary\n",
    "for cls in test_set:\n",
    "    # We get the index and path for that dataset.\n",
    "    for idx, inst_path in enumerate(test_set[cls]):\n",
    "        # Reading the csv into a dataframe.\n",
    "        df = pd.read_csv(inst_path, skiprows=5, header=None, names=inst_cols, usecols=range(7))\n",
    "         # Here we are creating a new row which will be appended to our dataframe having all the time domain features we require from this dataset.\n",
    "        new_row = []\n",
    "        new_row.append(len(extracted_df)+1)\n",
    "        # We are considering only the 6 time series data, ignoring the time column.\n",
    "        for i in range(1, 7):\n",
    "            new_row.extend([np.min(df[df.columns[i]]), np.max(df[df.columns[i]]), np.mean(df[df.columns[i]]), np.median(df[df.columns[i]]), np.std(df[df.columns[i]]), np.percentile(df[df.columns[i]], 25), np.percentile(df[df.columns[i]], 75)])\n",
    "        extracted_df.loc[len(extracted_df)] = new_row        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Instance</th>\n",
       "      <th>min1</th>\n",
       "      <th>max1</th>\n",
       "      <th>mean1</th>\n",
       "      <th>median1</th>\n",
       "      <th>std1</th>\n",
       "      <th>1st_quart1</th>\n",
       "      <th>3rd_quart1</th>\n",
       "      <th>min2</th>\n",
       "      <th>max2</th>\n",
       "      <th>...</th>\n",
       "      <th>std5</th>\n",
       "      <th>1st_quart5</th>\n",
       "      <th>3rd_quart5</th>\n",
       "      <th>min6</th>\n",
       "      <th>max6</th>\n",
       "      <th>mean6</th>\n",
       "      <th>median6</th>\n",
       "      <th>std6</th>\n",
       "      <th>1st_quart6</th>\n",
       "      <th>3rd_quart6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>35.00</td>\n",
       "      <td>47.40</td>\n",
       "      <td>43.954500</td>\n",
       "      <td>44.33</td>\n",
       "      <td>1.557210</td>\n",
       "      <td>43.00</td>\n",
       "      <td>45.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.70</td>\n",
       "      <td>...</td>\n",
       "      <td>1.997520</td>\n",
       "      <td>35.3625</td>\n",
       "      <td>36.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.493292</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.512971</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>33.00</td>\n",
       "      <td>47.75</td>\n",
       "      <td>42.179812</td>\n",
       "      <td>43.50</td>\n",
       "      <td>3.666840</td>\n",
       "      <td>39.15</td>\n",
       "      <td>45.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.845436</td>\n",
       "      <td>30.4575</td>\n",
       "      <td>36.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.613521</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.523771</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>33.00</td>\n",
       "      <td>45.75</td>\n",
       "      <td>41.678063</td>\n",
       "      <td>41.75</td>\n",
       "      <td>2.241152</td>\n",
       "      <td>41.33</td>\n",
       "      <td>42.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.83</td>\n",
       "      <td>...</td>\n",
       "      <td>2.408514</td>\n",
       "      <td>28.4575</td>\n",
       "      <td>31.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.383292</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.388759</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>37.00</td>\n",
       "      <td>48.00</td>\n",
       "      <td>43.454958</td>\n",
       "      <td>43.25</td>\n",
       "      <td>1.384653</td>\n",
       "      <td>42.50</td>\n",
       "      <td>45.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.58</td>\n",
       "      <td>...</td>\n",
       "      <td>2.486268</td>\n",
       "      <td>22.2500</td>\n",
       "      <td>24.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.26</td>\n",
       "      <td>0.679646</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.621885</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>36.25</td>\n",
       "      <td>48.00</td>\n",
       "      <td>43.969125</td>\n",
       "      <td>44.50</td>\n",
       "      <td>1.616677</td>\n",
       "      <td>43.31</td>\n",
       "      <td>44.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>...</td>\n",
       "      <td>3.314843</td>\n",
       "      <td>20.5000</td>\n",
       "      <td>23.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.96</td>\n",
       "      <td>0.555312</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.487318</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Instance   min1   max1      mean1  median1      std1  1st_quart1  \\\n",
       "0       1.0  35.00  47.40  43.954500    44.33  1.557210       43.00   \n",
       "1       2.0  33.00  47.75  42.179812    43.50  3.666840       39.15   \n",
       "2       3.0  33.00  45.75  41.678063    41.75  2.241152       41.33   \n",
       "3       4.0  37.00  48.00  43.454958    43.25  1.384653       42.50   \n",
       "4       5.0  36.25  48.00  43.969125    44.50  1.616677       43.31   \n",
       "\n",
       "   3rd_quart1  min2  max2  ...      std5  1st_quart5  3rd_quart5  min6  max6  \\\n",
       "0       45.00   0.0  1.70  ...  1.997520     35.3625       36.50   0.0  1.79   \n",
       "1       45.00   0.0  3.00  ...  3.845436     30.4575       36.33   0.0  2.18   \n",
       "2       42.75   0.0  2.83  ...  2.408514     28.4575       31.25   0.0  1.79   \n",
       "3       45.00   0.0  1.58  ...  2.486268     22.2500       24.00   0.0  5.26   \n",
       "4       44.67   0.0  1.50  ...  3.314843     20.5000       23.75   0.0  2.96   \n",
       "\n",
       "      mean6  median6      std6  1st_quart6  3rd_quart6  \n",
       "0  0.493292     0.43  0.512971        0.00        0.94  \n",
       "1  0.613521     0.50  0.523771        0.00        1.00  \n",
       "2  0.383292     0.43  0.388759        0.00        0.50  \n",
       "3  0.679646     0.50  0.621885        0.43        0.87  \n",
       "4  0.555312     0.49  0.487318        0.00        0.83  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As we can see we have our new dataset having time domain features for each of the 6 time series.\n",
    "extracted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 88 entries, 0 to 87\n",
      "Data columns (total 43 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Instance    88 non-null     float64\n",
      " 1   min1        88 non-null     float64\n",
      " 2   max1        88 non-null     float64\n",
      " 3   mean1       88 non-null     float64\n",
      " 4   median1     88 non-null     float64\n",
      " 5   std1        88 non-null     float64\n",
      " 6   1st_quart1  88 non-null     float64\n",
      " 7   3rd_quart1  88 non-null     float64\n",
      " 8   min2        88 non-null     float64\n",
      " 9   max2        88 non-null     float64\n",
      " 10  mean2       88 non-null     float64\n",
      " 11  median2     88 non-null     float64\n",
      " 12  std2        88 non-null     float64\n",
      " 13  1st_quart2  88 non-null     float64\n",
      " 14  3rd_quart2  88 non-null     float64\n",
      " 15  min3        88 non-null     float64\n",
      " 16  max3        88 non-null     float64\n",
      " 17  mean3       88 non-null     float64\n",
      " 18  median3     88 non-null     float64\n",
      " 19  std3        88 non-null     float64\n",
      " 20  1st_quart3  88 non-null     float64\n",
      " 21  3rd_quart3  88 non-null     float64\n",
      " 22  min4        88 non-null     float64\n",
      " 23  max4        88 non-null     float64\n",
      " 24  mean4       88 non-null     float64\n",
      " 25  median4     88 non-null     float64\n",
      " 26  std4        88 non-null     float64\n",
      " 27  1st_quart4  88 non-null     float64\n",
      " 28  3rd_quart4  88 non-null     float64\n",
      " 29  min5        88 non-null     float64\n",
      " 30  max5        88 non-null     float64\n",
      " 31  mean5       88 non-null     float64\n",
      " 32  median5     88 non-null     float64\n",
      " 33  std5        88 non-null     float64\n",
      " 34  1st_quart5  88 non-null     float64\n",
      " 35  3rd_quart5  88 non-null     float64\n",
      " 36  min6        88 non-null     float64\n",
      " 37  max6        88 non-null     float64\n",
      " 38  mean6       88 non-null     float64\n",
      " 39  median6     88 non-null     float64\n",
      " 40  std6        88 non-null     float64\n",
      " 41  1st_quart6  88 non-null     float64\n",
      " 42  3rd_quart6  88 non-null     float64\n",
      "dtypes: float64(43)\n",
      "memory usage: 30.2 KB\n"
     ]
    }
   ],
   "source": [
    "extracted_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### iii. Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lower Bound</th>\n",
       "      <th>Upper Bound</th>\n",
       "      <th>Standard Deviation</th>\n",
       "      <th>interval_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min1</th>\n",
       "      <td>8.308240</td>\n",
       "      <td>10.811091</td>\n",
       "      <td>9.515445</td>\n",
       "      <td>2.502851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max1</th>\n",
       "      <td>3.513822</td>\n",
       "      <td>5.444607</td>\n",
       "      <td>4.369322</td>\n",
       "      <td>1.930785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean1</th>\n",
       "      <td>4.757019</td>\n",
       "      <td>5.933797</td>\n",
       "      <td>5.305314</td>\n",
       "      <td>1.176778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median1</th>\n",
       "      <td>4.847203</td>\n",
       "      <td>6.059964</td>\n",
       "      <td>5.409056</td>\n",
       "      <td>1.212761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std1</th>\n",
       "      <td>1.587030</td>\n",
       "      <td>1.956356</td>\n",
       "      <td>1.760219</td>\n",
       "      <td>0.369326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st_quart1</th>\n",
       "      <td>5.629197</td>\n",
       "      <td>6.707413</td>\n",
       "      <td>6.118526</td>\n",
       "      <td>1.078216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3rd_quart1</th>\n",
       "      <td>4.413105</td>\n",
       "      <td>5.903851</td>\n",
       "      <td>5.109643</td>\n",
       "      <td>1.490746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max2</th>\n",
       "      <td>4.686502</td>\n",
       "      <td>5.469686</td>\n",
       "      <td>5.033882</td>\n",
       "      <td>0.783184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean2</th>\n",
       "      <td>1.434065</td>\n",
       "      <td>1.744888</td>\n",
       "      <td>1.565194</td>\n",
       "      <td>0.310823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median2</th>\n",
       "      <td>1.269006</td>\n",
       "      <td>1.576937</td>\n",
       "      <td>1.404197</td>\n",
       "      <td>0.307932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std2</th>\n",
       "      <td>0.819698</td>\n",
       "      <td>0.959327</td>\n",
       "      <td>0.878152</td>\n",
       "      <td>0.139630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st_quart2</th>\n",
       "      <td>0.854644</td>\n",
       "      <td>1.055774</td>\n",
       "      <td>0.940994</td>\n",
       "      <td>0.201130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3rd_quart2</th>\n",
       "      <td>1.942446</td>\n",
       "      <td>2.343433</td>\n",
       "      <td>2.113157</td>\n",
       "      <td>0.400987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min3</th>\n",
       "      <td>2.787190</td>\n",
       "      <td>3.136929</td>\n",
       "      <td>2.939616</td>\n",
       "      <td>0.349739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max3</th>\n",
       "      <td>4.260291</td>\n",
       "      <td>5.540192</td>\n",
       "      <td>4.847358</td>\n",
       "      <td>1.279901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean3</th>\n",
       "      <td>3.502665</td>\n",
       "      <td>4.579534</td>\n",
       "      <td>3.985540</td>\n",
       "      <td>1.076869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median3</th>\n",
       "      <td>3.520204</td>\n",
       "      <td>4.609897</td>\n",
       "      <td>4.013397</td>\n",
       "      <td>1.089693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std3</th>\n",
       "      <td>0.765197</td>\n",
       "      <td>1.123835</td>\n",
       "      <td>0.940335</td>\n",
       "      <td>0.358638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st_quart3</th>\n",
       "      <td>3.714819</td>\n",
       "      <td>4.789481</td>\n",
       "      <td>4.196608</td>\n",
       "      <td>1.074662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3rd_quart3</th>\n",
       "      <td>3.642207</td>\n",
       "      <td>4.788664</td>\n",
       "      <td>4.147858</td>\n",
       "      <td>1.146456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max4</th>\n",
       "      <td>1.993803</td>\n",
       "      <td>2.379708</td>\n",
       "      <td>2.171183</td>\n",
       "      <td>0.385905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean4</th>\n",
       "      <td>1.103051</td>\n",
       "      <td>1.249866</td>\n",
       "      <td>1.159470</td>\n",
       "      <td>0.146815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median4</th>\n",
       "      <td>1.083586</td>\n",
       "      <td>1.230050</td>\n",
       "      <td>1.139058</td>\n",
       "      <td>0.146464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std4</th>\n",
       "      <td>0.427189</td>\n",
       "      <td>0.491706</td>\n",
       "      <td>0.455156</td>\n",
       "      <td>0.064517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st_quart4</th>\n",
       "      <td>0.791543</td>\n",
       "      <td>0.908789</td>\n",
       "      <td>0.838813</td>\n",
       "      <td>0.117246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3rd_quart4</th>\n",
       "      <td>1.468622</td>\n",
       "      <td>1.663947</td>\n",
       "      <td>1.543658</td>\n",
       "      <td>0.195325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min5</th>\n",
       "      <td>4.681205</td>\n",
       "      <td>7.804522</td>\n",
       "      <td>6.089107</td>\n",
       "      <td>3.123317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max5</th>\n",
       "      <td>4.883732</td>\n",
       "      <td>6.710332</td>\n",
       "      <td>5.708524</td>\n",
       "      <td>1.826600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean5</th>\n",
       "      <td>4.615827</td>\n",
       "      <td>6.873581</td>\n",
       "      <td>5.643253</td>\n",
       "      <td>2.257753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median5</th>\n",
       "      <td>4.684374</td>\n",
       "      <td>7.047562</td>\n",
       "      <td>5.780655</td>\n",
       "      <td>2.363188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std5</th>\n",
       "      <td>0.821894</td>\n",
       "      <td>1.227105</td>\n",
       "      <td>1.017996</td>\n",
       "      <td>0.405211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st_quart5</th>\n",
       "      <td>4.924749</td>\n",
       "      <td>7.339719</td>\n",
       "      <td>6.061727</td>\n",
       "      <td>2.414970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3rd_quart5</th>\n",
       "      <td>4.502695</td>\n",
       "      <td>6.686003</td>\n",
       "      <td>5.500200</td>\n",
       "      <td>2.183308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min6</th>\n",
       "      <td>0.013125</td>\n",
       "      <td>0.091154</td>\n",
       "      <td>0.045577</td>\n",
       "      <td>0.078029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max6</th>\n",
       "      <td>2.258452</td>\n",
       "      <td>2.769868</td>\n",
       "      <td>2.504568</td>\n",
       "      <td>0.511415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean6</th>\n",
       "      <td>1.088116</td>\n",
       "      <td>1.241551</td>\n",
       "      <td>1.148232</td>\n",
       "      <td>0.153434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median6</th>\n",
       "      <td>1.017582</td>\n",
       "      <td>1.169325</td>\n",
       "      <td>1.080284</td>\n",
       "      <td>0.151743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std6</th>\n",
       "      <td>0.487080</td>\n",
       "      <td>0.552708</td>\n",
       "      <td>0.514132</td>\n",
       "      <td>0.065628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st_quart6</th>\n",
       "      <td>0.706536</td>\n",
       "      <td>0.822627</td>\n",
       "      <td>0.754261</td>\n",
       "      <td>0.116091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3rd_quart6</th>\n",
       "      <td>1.437929</td>\n",
       "      <td>1.631634</td>\n",
       "      <td>1.514918</td>\n",
       "      <td>0.193705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Lower Bound  Upper Bound  Standard Deviation  interval_width\n",
       "min1           8.308240    10.811091            9.515445        2.502851\n",
       "max1           3.513822     5.444607            4.369322        1.930785\n",
       "mean1          4.757019     5.933797            5.305314        1.176778\n",
       "median1        4.847203     6.059964            5.409056        1.212761\n",
       "std1           1.587030     1.956356            1.760219        0.369326\n",
       "1st_quart1     5.629197     6.707413            6.118526        1.078216\n",
       "3rd_quart1     4.413105     5.903851            5.109643        1.490746\n",
       "min2           0.000000     0.000000            0.000000        0.000000\n",
       "max2           4.686502     5.469686            5.033882        0.783184\n",
       "mean2          1.434065     1.744888            1.565194        0.310823\n",
       "median2        1.269006     1.576937            1.404197        0.307932\n",
       "std2           0.819698     0.959327            0.878152        0.139630\n",
       "1st_quart2     0.854644     1.055774            0.940994        0.201130\n",
       "3rd_quart2     1.942446     2.343433            2.113157        0.400987\n",
       "min3           2.787190     3.136929            2.939616        0.349739\n",
       "max3           4.260291     5.540192            4.847358        1.279901\n",
       "mean3          3.502665     4.579534            3.985540        1.076869\n",
       "median3        3.520204     4.609897            4.013397        1.089693\n",
       "std3           0.765197     1.123835            0.940335        0.358638\n",
       "1st_quart3     3.714819     4.789481            4.196608        1.074662\n",
       "3rd_quart3     3.642207     4.788664            4.147858        1.146456\n",
       "min4           0.000000     0.000000            0.000000        0.000000\n",
       "max4           1.993803     2.379708            2.171183        0.385905\n",
       "mean4          1.103051     1.249866            1.159470        0.146815\n",
       "median4        1.083586     1.230050            1.139058        0.146464\n",
       "std4           0.427189     0.491706            0.455156        0.064517\n",
       "1st_quart4     0.791543     0.908789            0.838813        0.117246\n",
       "3rd_quart4     1.468622     1.663947            1.543658        0.195325\n",
       "min5           4.681205     7.804522            6.089107        3.123317\n",
       "max5           4.883732     6.710332            5.708524        1.826600\n",
       "mean5          4.615827     6.873581            5.643253        2.257753\n",
       "median5        4.684374     7.047562            5.780655        2.363188\n",
       "std5           0.821894     1.227105            1.017996        0.405211\n",
       "1st_quart5     4.924749     7.339719            6.061727        2.414970\n",
       "3rd_quart5     4.502695     6.686003            5.500200        2.183308\n",
       "min6           0.013125     0.091154            0.045577        0.078029\n",
       "max6           2.258452     2.769868            2.504568        0.511415\n",
       "mean6          1.088116     1.241551            1.148232        0.153434\n",
       "median6        1.017582     1.169325            1.080284        0.151743\n",
       "std6           0.487080     0.552708            0.514132        0.065628\n",
       "1st_quart6     0.706536     0.822627            0.754261        0.116091\n",
       "3rd_quart6     1.437929     1.631634            1.514918        0.193705"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is the function to calculate the confidence interval for each of the time domain features.\n",
    "def cal_ci(data, ci=90):\n",
    "    data = np.array(data).flatten()\n",
    "    res = bs.bootstrap(data, stat_func=bs_stats.std, alpha=(100-ci)/100)\n",
    "    return res.lower_bound, res.upper_bound, res.value\n",
    "\n",
    "# Here we are computing the confidence intervals for each of the time domain feature\n",
    "ci_intervals = {col: cal_ci(extracted_df[col]) for col in extracted_df.columns[1:]}\n",
    "\n",
    "# Creating a dataframe to display our results.\n",
    "df_ci = pd.DataFrame(ci_intervals, index=['Lower Bound', 'Upper Bound', 'Standard Deviation']).T\n",
    "df_ci[\"interval_width\"] = df_ci[\"Upper Bound\"] - df_ci[\"Lower Bound\"]\n",
    "df_ci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### iv. Select Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 11\n"
     ]
    }
   ],
   "source": [
    "# Here we are checking if each of the time domain features are rightly or leftly skewed.\n",
    "skw_val = extracted_df.apply(skew)\n",
    "count_p = 0\n",
    "count_n = 0\n",
    "for val in skw_val:\n",
    "    if val > 0:\n",
    "        count_p += 1\n",
    "    elif val < 0:\n",
    "        count_n += 1\n",
    "\n",
    "print(count_p, count_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on my judgement i will select Mean, Standard Deviation and 3rd Quartile as the three most important time domain features. The reasoning is as follows:\n",
    "\n",
    "<ul>\n",
    "    <li> Mean : This tell us the average of the time series distribution.\n",
    "    <li> Standard Deviation : This will tell us the variability and spread of the data points around the mean.\n",
    "    <li> 3rd Quartile : This will tell us about the right-skewness of the distribution. We take 3rd Quartile as compared to 1st Quartile as we can see above most of our features are right skewed.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ISLR 3.7.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Linear Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RSS will be lower for cubic regression compared to linear regression for the training data, because even though the true relation is linear, the cubic model will be more flexible, so it can fit the training data more closely thus capturing noise and random fluctuations, resulting in lower RSS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Linear Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RSS will be lower for the linear regression compared to cubic regression for the testing data, because, the true relation is linear and due to overfitting the cubic model will have captured some noise thus resulting in higher RSS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Not Linear Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RSS will be lower for the cubic regression compared to the linear regression, because the we know that the true relation is non-linear, thus the cubic model will be able to capture the non-linearity of the data better compared to the linear model, thus resulting in lower RSS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Not Linear Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is not enough information to predict the RSS. Since, we dont know the degree of non-linearity of the true relation, the RSS can be lower for cubic model, if the degree of non-linerity is sufficiently higher, but otherwise the RSS will be higher since the cubic model can overfit the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ISLR 3.7.3 - Extra Practice "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) option iii. (For a fixed value of IQ and GPA, males earn more on average than females provided that the GPA is high enough) is correct, since if we input the value of x3 in the equation and find the difference between that of female and male we get the equation -> Sal(Female) - Sal(Male) = 35 - 10 * GPA. Hence, we can observe that for lower value of GPA, Female will have a higher salary on avg compared to male, but for higher values of GPA, Male will have a higher salary on avg compared to female.\n",
    "\n",
    "b) Sal(Female) = 50 + 20 * (4) + 0.07 * (110) + 35 * (1) + 0.01 * (4.0) * (110) − 10 * (4.0) * (1) = 137.1. Thus the predicted Salary of female will be 137,100 USD.\n",
    "\n",
    "c) False, Since we can determine the impact of a term based only on the magnitude of their coefficient, we would need check the p-value of the term against the confidence interval to determine its statistical significances.\n",
    "​\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ISLR 3.7.5 - Extra Practice "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "294.435px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
